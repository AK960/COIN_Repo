{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3672feb08161c328",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "id": "623eba49e8f8a0d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T15:29:37.354843Z",
     "start_time": "2025-05-23T15:29:37.347289Z"
    }
   },
   "source": [
    "# import all libraries for notebook\n",
    "import pandas as pd\n",
    "from pandas import json_normalize\n",
    "import numpy as np\n",
    "import re\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "style.use('ggplot')\n",
    "from textblob import TextBlob\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "#nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
    "import json\n",
    "from json import loads, dumps\n",
    "from pprint import pprint"
   ],
   "outputs": [],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "id": "7bf956b2a1f07fe5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T15:23:05.671131Z",
     "start_time": "2025-05-23T15:23:03.444545Z"
    }
   },
   "source": [
    "# Import files\n",
    "df_replies = pd.read_csv('../data/twitter/tweets_isReply.csv', dtype={'id': 'object'}, low_memory=False)\n",
    "df_tweets = pd.read_csv('../data/twitter/tweets_isTweet.csv', dtype={'id': 'object'}, low_memory=False)\n",
    "\n",
    "# Create and prepare Dataframes\n",
    "# Original tweets\n",
    "df_nonQuotedTweets = df_tweets[df_tweets['quoted_tweet'].isna()]\n",
    "df_nonQuotedTweets = df_nonQuotedTweets.rename(columns={'id': 'tweet_id', 'text': 'tweet_text'})\n",
    "# Quoted tweets\n",
    "df_quotedTweets = df_tweets[['id', 'text', 'quoted_tweet']].dropna(subset=['quoted_tweet'])\n",
    "df_quotedTweets = df_quotedTweets.rename(columns={'id': 'tweet_id', 'text': 'tweet_text'})\n",
    "# Cards\n",
    "df_tweetsWithCard = df_tweets[['id', 'card']]\n",
    "df_tweetsWithCard = df_tweetsWithCard.dropna(subset=['card'])\n",
    "df_tweetsWithCard = df_tweetsWithCard.rename(columns={'id': 'tweet_id'})"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T15:26:55.257688Z",
     "start_time": "2025-05-23T15:26:55.232418Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"[Max][df_tweets] \", df_tweets['createdAt'].max(), \"\\n\")\n",
    "print(\"[Min][df_tweets] \", df_tweets['createdAt'].min(), \"\\n\")\n",
    "print(\"[Max][df_replies] \", df_replies['createdAt'].max(), \"\\n\")\n",
    "print(\"[Max][df_replies] \", df_replies['createdAt'].min(), \"\\n\")"
   ],
   "id": "983ef9e857e6ff15",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Max][df_tweets]  Wed Sep 27 23:06:04 +0000 2023 \n",
      "\n",
      "[Min][df_tweets]  Fri Apr 04 02:42:55 +0000 2025 \n",
      "\n",
      "[Max][df_replies]  Wed Sep 27 23:32:38 +0000 2023 \n",
      "\n",
      "[Max][df_replies]  Fri Apr 04 02:22:25 +0000 2025 \n",
      "\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "id": "5503eeb0ff5fa5bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T15:28:22.393408Z",
     "start_time": "2025-05-23T15:28:22.373958Z"
    }
   },
   "source": [
    "# Functions\n",
    "# Removing unnecessary data\n",
    "def data_processing(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"https\\S+|www\\S+httpss\\S+\", '', text, flags=re.MULTILINE) # Remove Url\n",
    "    text = re.sub(r\"\\@w+|\\#\", '', text) # remove @ and #\n",
    "    text = re.sub(r\"[^\\w\\s]\", '', text) # remove punctuation\n",
    "    text_tokens = text.split()\n",
    "    filtered_text = [w for w in text_tokens if not w in stop_words]\n",
    "    return \" \".join(filtered_text)\n",
    "\n",
    "# Reduction of dimensionality by abstracting word to word stem\n",
    "stemmer = PorterStemmer() \n",
    "def stemming(data):\n",
    "    text = [stemmer.stem(word) for word in data]\n",
    "    return data\n",
    "\n",
    "def polarity(text):\n",
    "    return TextBlob(text).sentiment.polarity\n",
    "\n",
    "def sentiment(label):\n",
    "    if label < 0:\n",
    "        return \"negative\"\n",
    "    elif label == 0:\n",
    "        return \"neutral\"\n",
    "    elif label > 0:\n",
    "        return \"positive\"\n",
    "    return None"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "id": "d048b1e351db2690",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T15:28:26.529602Z",
     "start_time": "2025-05-23T15:28:24.670264Z"
    }
   },
   "source": [
    "# Prepare quoted tweets\n",
    "\n",
    "# Normalize quoted_tweet column\n",
    "df_quotedTweets_normalized = pd.json_normalize(\n",
    "    df_quotedTweets['quoted_tweet'].apply(json.loads),\n",
    "    sep='_'\n",
    ")\n",
    "\n",
    "# Link both dataframes by index\n",
    "df_quotedTweets_normalized.index = df_quotedTweets.index\n",
    "\n",
    "# Rename columns\n",
    "df_quotedTweets_normalized.columns = ['quoted_tweet_' + col for col in df_quotedTweets_normalized.columns]\n",
    "\n",
    "# Concatenate the two dataframes\n",
    "df_final = pd.concat([\n",
    "    df_quotedTweets[['tweet_id', 'tweet_text']],\n",
    "    df_quotedTweets_normalized[['quoted_tweet_id', 'quoted_tweet_text']]\n",
    "], axis=1)\n",
    "\n",
    "df_final.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "              tweet_id                                         tweet_text  \\\n",
       "2  1917225430702240067                                 This is a big deal   \n",
       "4  1917103264417649121                                               Whoa   \n",
       "5  1917099777327829386  Next week, Grok 3.5 early beta release to Supe...   \n",
       "6  1917071819003334728                       It is an existential crisis!   \n",
       "9  1917040536378335721  Starlink is trying out a service plan commitme...   \n",
       "\n",
       "       quoted_tweet_id                                  quoted_tweet_text  \n",
       "2  1917223651625099407  Last week, Treasury went live with its first a...  \n",
       "4  1917011279757066291  ðŸš¨THE INVISIBLE PUPPET MASTERS: AI'S DISTURBING...  \n",
       "5  1917011847623987257  ðŸš¨GROK 3 SENDS USAGE SOARING â€“ 10X SPIKE IN DOW...  \n",
       "6  1917059115417014780  A friendly reminder to make more babies!\\n\\nðŸ‡¯ðŸ‡µ...  \n",
       "9  1917029886432317947  $0 for the Standard Kit with 12-month resident...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>quoted_tweet_id</th>\n",
       "      <th>quoted_tweet_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1917225430702240067</td>\n",
       "      <td>This is a big deal</td>\n",
       "      <td>1917223651625099407</td>\n",
       "      <td>Last week, Treasury went live with its first a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1917103264417649121</td>\n",
       "      <td>Whoa</td>\n",
       "      <td>1917011279757066291</td>\n",
       "      <td>ðŸš¨THE INVISIBLE PUPPET MASTERS: AI'S DISTURBING...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1917099777327829386</td>\n",
       "      <td>Next week, Grok 3.5 early beta release to Supe...</td>\n",
       "      <td>1917011847623987257</td>\n",
       "      <td>ðŸš¨GROK 3 SENDS USAGE SOARING â€“ 10X SPIKE IN DOW...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1917071819003334728</td>\n",
       "      <td>It is an existential crisis!</td>\n",
       "      <td>1917059115417014780</td>\n",
       "      <td>A friendly reminder to make more babies!\\n\\nðŸ‡¯ðŸ‡µ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1917040536378335721</td>\n",
       "      <td>Starlink is trying out a service plan commitme...</td>\n",
       "      <td>1917029886432317947</td>\n",
       "      <td>$0 for the Standard Kit with 12-month resident...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "id": "970ec76d79dc3283",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T15:31:31.973039Z",
     "start_time": "2025-05-23T15:31:27.802749Z"
    }
   },
   "source": [
    "# Pre-processing\n",
    "df_final.quoted_tweet_text = df_final['quoted_tweet_text'].apply(data_processing)\n",
    "df_final.tweet_text = df_final['tweet_text'].apply(data_processing)\n",
    "\n",
    "# Stemming\n",
    "df_final['quoted_tweet_text'] = df_final['quoted_tweet_text'].apply(lambda x: stemming(x))\n",
    "\n",
    "# Polarity\n",
    "df_final['polarity'] = df_final['quoted_tweet_text'].apply(polarity)\n",
    "\n",
    "# Sentiment \n",
    "df_final['sentiment'] = df_final['polarity'].apply(sentiment)\n",
    "\n",
    "print(df_final.head(), \"\\n\")\n",
    "print(df_final.shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              tweet_id                                         tweet_text  \\\n",
      "2  1917225430702240067                                           big deal   \n",
      "4  1917103264417649121                                               whoa   \n",
      "5  1917099777327829386  next week grok 35 early beta release supergrok...   \n",
      "6  1917071819003334728                                 existential crisis   \n",
      "9  1917040536378335721  starlink trying service plan commitment exchan...   \n",
      "\n",
      "       quoted_tweet_id                                  quoted_tweet_text  \\\n",
      "2  1917223651625099407  last week treasury went live first automated p...   \n",
      "4  1917011279757066291  invisible puppet masters ais disturbing new ro...   \n",
      "5  1917011847623987257  grok 3 sends usage soaring 10x spike downloads...   \n",
      "6  1917059115417014780  friendly reminder make babies japans total fer...   \n",
      "9  1917029886432317947  0 standard kit 12month residential service pla...   \n",
      "\n",
      "   polarity sentiment  \n",
      "2 -0.005519  negative  \n",
      "4  0.066279  positive  \n",
      "5  0.066667  positive  \n",
      "6  0.075000  positive  \n",
      "9  0.075000  positive   \n",
      "\n",
      "(8349, 6)\n"
     ]
    }
   ],
   "execution_count": 25
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coin",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
