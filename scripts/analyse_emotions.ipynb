{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2ac6fbebcfa0983",
   "metadata": {},
   "source": [
    "# Emotion Analysis"
   ]
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Imports\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import json_normalize, Series\n",
    "import numpy as np\n",
    "import re\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "from sympy.strategies.core import switch\n",
    "style.use('ggplot')\n",
    "from textblob import TextBlob\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
    "import json\n",
    "from json import loads, dumps\n",
    "from pprint import pprint\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "from tqdm import tqdm\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c37722425b3f995",
   "metadata": {},
   "source": [
    "### Prepare dataframe for analysis\n",
    "# Import dataset\n",
    "df_tweets = pd.read_csv(\n",
    "    '../data/twitter/tweets_isTweet.csv',\n",
    "    dtype={'id': 'object'},\n",
    "    low_memory=False\n",
    ")\n",
    "df_tweets = df_tweets[['id', 'createdAt', 'text', 'quoted_tweet']]\n",
    "df_tweets = df_tweets.rename(columns={'id': 'tweet_id', 'text': 'tweet_text'})\n",
    "\n",
    "# Normalize json column\n",
    "quoted_tweets_normalized = pd.json_normalize(\n",
    "    df_tweets['quoted_tweet'].apply(\n",
    "        lambda x: json.loads(x) if pd.notna(x) and isinstance(x, str) else None\n",
    "    )\n",
    ")\n",
    "quoted_tweets_normalized = quoted_tweets_normalized.rename(columns={'id': 'quoted_tweet_id', 'text': 'quoted_tweet_text'})\n",
    "\n",
    "# Link by index\n",
    "df_tweets.index = quoted_tweets_normalized.index\n",
    "\n",
    "# Concat both dataframes\n",
    "df_tweets_normalized = pd.concat([\n",
    "    df_tweets[['tweet_id', 'createdAt', 'tweet_text']],\n",
    "    quoted_tweets_normalized[['quoted_tweet_id', 'quoted_tweet_text']]\n",
    "], axis=1)\n",
    "\n",
    "# View data\n",
    "df_tweets_normalized.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c3f0b8cab02dc451",
   "metadata": {},
   "source": [
    "### Pre-process data for the analysis\n",
    "## Variables\n",
    "ekman_emotions = ['anger', 'fear', 'joy', 'sadness', 'disgust', 'surprise']\n",
    "\n",
    "## Classifier\n",
    "# Load Hugging Face's emotion classifier\n",
    "print(\"[Info]\")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "classifier = pipeline(\"text-classification\", model=\"bhadresh-savani/bert-base-uncased-emotion\", top_k=None, device=0 if device == \"cuda\" else -1)\n",
    "\n",
    "## Functions\n",
    "# Removing noise from the text\n",
    "def remove_noise(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"https\\S+|www\\S+httpss\\S+\", '', text, flags=re.MULTILINE) # Remove Url\n",
    "    text = re.sub(r\"\\@w+|\\#\", '', text) # remove @ and #\n",
    "    text = re.sub(r\"[^\\w\\s]\", '', text) # remove punctuation\n",
    "    text_tokens = text.split()\n",
    "    filtered_text = [w for w in text_tokens if not w in stop_words]\n",
    "    return \" \".join(filtered_text)\n",
    "\n",
    "# Reduction of dimensionality by abstracting word to word stem\n",
    "stemmer = PorterStemmer()\n",
    "def stem_words(text):\n",
    "    words = text.split()\n",
    "    stemmed_text = [stemmer.stem(word) for word in words]\n",
    "    return stemmed_text\n",
    "\n",
    "def truncate_text(text, max_length=512):\n",
    "    words = text.split()\n",
    "    return \" \".join(words[:max_length])\n",
    "\n",
    "def compute_emotions(text):\n",
    "    if not isinstance(text, str) or text.strip() == \"\":\n",
    "        print(\"[ComputeEmotions] Empty cell after data cleaning. Returning 0.0 for all emotions.\")\n",
    "        return {emotion: 0.0 for emotion in ekman_emotions}\n",
    "\n",
    "    try:\n",
    "    #    # Remove noise from text - when empty afterwards, return 0.0 for all emotions\n",
    "    #    cleaned_text = remove_noise(text)\n",
    "    #    if not cleaned_text.strip(): \n",
    "    #        return {emotion: 0.0 for emotion in ekman_emotions}\n",
    "    #    \n",
    "    #    # Remove dimensionality by stemming and converts list from stemming back to string for classification\n",
    "    #    cleaned_text = \" \".join(stem_words(cleaned_text)) \n",
    "\n",
    "        # Classify emotions using the Hugging Face pipeline and handle errors\n",
    "        results = classifier(text)[0]\n",
    "        if not results or not isinstance(results, list) or len(results[0]) == 0:\n",
    "            return {emotion: 0.0 for emotion in ekman_emotions}\n",
    "\n",
    "        emotion_scores = {result['label']: result['score'] for result in results}\n",
    "        return {emotion: emotion_scores.get(emotion, 0.0) for emotion in ekman_emotions}\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[ComputeEmotions] Error while processing text: {text[:20]}... Error: {e}\")\n",
    "        return {emotion: 0.0 for emotion in ekman_emotions}\n",
    "\n",
    "def append_emotions(df, text_column):\n",
    "    if text_column not in df.columns:\n",
    "        raise ValueError(f\"[AppendEmotions] Column '{text_column}' not found in DataFrame.\")\n",
    "    \n",
    "    print(\"[AppendEmotions] Computing emotions for column:\", text_column)\n",
    "\n",
    "    cleaned_column = f\"{text_column}_cleaned\"\n",
    "    df[cleaned_column] = df[text_column].apply(\n",
    "        lambda x: \" \".join(stem_words(remove_noise(x))) if isinstance(x, str) and x.strip() else \"\"\n",
    "    )\n",
    "\n",
    "    # Truncate text if cleaned text exceeds 512 tokens\n",
    "    if (df[cleaned_column].str.split().str.len() > 512).any():\n",
    "        print(\"[AppendEmotions] At least one row with more than 512 tokens - truncating text ...\")\n",
    "        df[cleaned_column] = df[cleaned_column].apply(lambda x: truncate_text(x, max_length=512))\n",
    "\n",
    "    emotion_scores = [compute_emotions(text) for text in tqdm(df[cleaned_column], desc=\"[AppendEmotions] Processing emotions\")]\n",
    "    emotions_df = pd.DataFrame(emotion_scores)\n",
    "    emotions_df.index = df.index\n",
    "    emotions_df.columns = [f\"{text_column}_{emotion}\" for emotion in ekman_emotions]\n",
    "    \n",
    "    # Add dominant emotion column\n",
    "    dominant = emotions_df.idxmax(axis=1).apply(lambda x: x.split('_')[-1])\n",
    "    all_zero = (emotions_df == 0.0).all(axis=1)\n",
    "    dominant[all_zero] = np.nan\n",
    "    emotions_df[f\"{text_column}_dominant_emotion\"] = dominant\n",
    "\n",
    "    # Insert right hand of input text_column\n",
    "    insert_at = df.columns.get_loc(text_column) + 1\n",
    "\n",
    "    # DataFrame in drei Teile splitten und zusammenf√ºgen\n",
    "    left = df.iloc[:, :insert_at]\n",
    "    right = df.iloc[:, insert_at:].drop(columns=[cleaned_column], errors='ignore')\n",
    "    result_df = pd.concat([left, df[[cleaned_column]], emotions_df, right], axis=1)\n",
    "\n",
    "    return result_df\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9db3676b",
   "metadata": {},
   "source": [
    "# Perform emotion analysis for columns specified\n",
    "for col in ['tweet_text', 'quoted_tweet_text']:\n",
    "    df_tweets_normalized = append_emotions(df_tweets_normalized, text_column=col)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4439361d",
   "metadata": {},
   "source": [
    "# Safe the DataFrame with emotions to csv\n",
    "df_tweets_normalized.to_csv('../data/twitter/tweets_isTweet_emotions.csv', index=False)"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coin",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
